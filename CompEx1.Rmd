---
subtitle: "TMA4268 Statistical Learning V2018"
title: "Compulsory exercise 1: Group 21"
author: "JÃ¸rgen Opheim, Ole-Andreas Sandnes and Sander Coates"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: #3rd letter intentation hierarchy
  # prettydoc::html_pretty:
  #   theme: tactile
  #   highlight: github
  pdf_document:
editor_options: 
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1 - Core concepts in statistical learning [2 points]

## a) Training and test MSE [1 point]

* *Figure 2* shows that variance is reduced for increased values of $K$, but at the cost of increased bias.
* A low value of $K$ gives the most flexible fit.

* As expected from lower flexibility for higher $K$, the training MSE increases with $K$. This is due to the reduced fitting of the model to the specific data. However, when introducing the test data, overfitting by a too flexible model leads to increased test MSE for the lowest values of $K$. This suggest a slightly less flexible and thus less biased model (more on the bias-variance trade-off later) is better.
* By observation, it seems that $K = 3$ gives the lowest test MSE, and hence is the best choice of K for modelling $f(x)$ based on observed values $y = f(x) + \epsilon$.

## b) Bias-variance trade-off [1 point]

* The variance is calculated by use of R's own function ```var``` over all experiments $M$ for a given $x$ and $K$. The squared bias is then found by squaring the difference between the mean over all $M$ experiments for a given $x$ and $K$ and the true value of $y$ for that particular $x$ (equal for all values of $K$). \textcolor{red}{Add some formulae?}
    
* As flexibility increases (K decreases)
    + the squared bias decreases (as expected by less fitting to the specific training data),
    + variance increases (as expected from closer fitting to specific training data),
    + and the irreducible error is left unchanged. The irreducible error is caused by variance of the underlying data and is not affected by modelling.
  
* By observation of the total test MSE the optimal value of $K$ seems to be $K = 3$ (for which the total error is smallest), as suggested in a).

* [Extra] In $Figure 5$ the optimal value of $K$ seems to be greater than that previously identified. This is however for four specific values of $x$, none of which are at the boundaries of $x$'s domain ($x \in [-3, 3]$). \textcolor{red}{Possible to do analysis for more values of $x$ to test validity of reasoning?}

# Problem 2 - Linear regression [4 points]

Here you see an R chunk that is evaluated (when knitting) and code is displayed.

```{r,echo=TRUE,eval=FALSE}
library(ggplot2)
data = read.table("https://www.math.ntnu.no/emner/TMA4268/2018v/data/SYSBPreg3uid.txt")
dim(data)
colnames(data)
modelA=lm(-1/sqrt(SYSBP) ~ .,data = data)
summary(modelA)
```

## a) Understanding model output [1 point]

* The equation for `modelA` is
$$Y_i= \beta_0 + \sum_x \beta_{x}  x_{i} + \varepsilon_i,$$ where $i=1,2,...,n$, $x \in \{$`SEX`, `AGE`, `CURSMOKE`, `BMI`, `TOTCHOL`, `BPMEDS`$\}$, and $Y_i =$ `-1/sqrt(SYSBP_i)`.

* In the summary output,
  + `Estimate` refers to the least squares coefficient estimates for the intercept ($\hat{beta}_0$) and covariates ($\hat{\beta}_x, x \in \{$`SEX`, `AGE`, `CURSMOKE`, `BMI`, `TOTCHOL`, `BPMEDS`$\}$). In particular, `Intercept` gives the expected response variable when all covariates are zero. The other estimates are interpreted as the average effect on $Y$ of a marginal (unit) increase in the respective covariate, holding all others fixed.
  + The `Std. Error` refers to a systematic error in the estimate of the coefficients by inference from the training data, and is calculated as

$$\text{SE}(\hat\beta_0)^2 = \sigma^2\bigg[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i = 1}^n(x_i - \bar{x})^2}\bigg], \text{SE}(\hat\beta_1)^2 = \frac{\sigma^2}{\sum_{i = 1}^n(x_i - \bar{x})^2},$$
\textcolor{red}{The above formulae are for simple linear regression... What is the equivalent for multiple regression?}

+ The `t value` refers to the t-statistic given by

$$t = \frac{\hat\beta_1 - 0}{\text{SE}(\hat\beta_1)}$$
by which we test for each covariate whether or not its coefficient estimate is different from zero or not. In other words, the `t value` gives a measure of how many standard deviations the observed estimate is away from zero. A large `t value` for a covariate suggests the covariate does affect the response variable.


+ `Pr(>|t|)` gives the probability of observing a more extreme coefficient than that estimated, for a student t distribution. It is the *p value*, and a standardized way of expressing the probability of type I error (false positives), i.e. rejecting the null hypothesis of a zero coefficient and concluding instead that the covariate affects the response variable.

+ \textcolor{red}{Residual standard error}

+ The `F-statistic` provides a way of testing, for mulitple regression, whether all coefficents are zero (null hypothesis). The test is performed by calculating

$$F = \frac{\text{TSS} - \text{RSS}/p}{\text{RSS}/(n - p - 1)},$$

where $\text{TSS} = \sum(y_i - \bar{y})^2$ (total sum of squares) and $\text{RSS} = \sum(y_i - \hat{y}_i)^2$ (residual sum of squares). A large F-statistic suggests that not all coefficients are zero, and that at least one covariate affects the response variable.

\textcolor{red}{Improve assignment by relating above ``definitions'' to observed values in output summary?}

## b) Model fit [1 point]
## c) Confidence interval and hypothesis test [1 points]
## d) Prediction [1 point]